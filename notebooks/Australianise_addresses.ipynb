{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\3434893485.py:5: DtypeWarning: Columns (7,13,15,16,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(filename, delimiter='|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of ../data/VIC_Address_Data/VIC_ADDRESS_DETAIL_psv.psv: 3949.19 MB\n",
      "Memory usage of ../data/VIC_Address_Data/VIC_STREET_LOCALITY_psv.psv: 79.12 MB\n",
      "Memory usage of ../data/VIC_Address_Data/VIC_LOCALITY_psv.psv: 0.78 MB\n",
      "Memory usage of ../data/VIC_Address_Data/VIC_STATE_psv.psv: 0.00 MB\n",
      "Memory usage of ../data/VIC_Address_Data/VIC_ADDRESS_DEFAULT_GEOCODE_psv.psv: 845.16 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to load data and calculate its memory usage\n",
    "def load_psv_and_report_memory(filename):\n",
    "    data = pd.read_csv(filename, delimiter='|')\n",
    "    memory = data.memory_usage(deep=True).sum() / (1024 ** 2)  # Convert bytes to megabytes\n",
    "    print(f\"Memory usage of {filename}: {memory:.2f} MB\")\n",
    "    return data\n",
    "\n",
    "# Path to the data directory\n",
    "data_dir = '../data/VIC_Address_Data/'\n",
    "\n",
    "# Load data files with memory usage report\n",
    "address_detail = load_psv_and_report_memory(data_dir + 'VIC_ADDRESS_DETAIL_psv.psv')\n",
    "street_locality = load_psv_and_report_memory(data_dir + 'VIC_STREET_LOCALITY_psv.psv')\n",
    "locality = load_psv_and_report_memory(data_dir + 'VIC_LOCALITY_psv.psv')\n",
    "state = load_psv_and_report_memory(data_dir + 'VIC_STATE_psv.psv')\n",
    "address_geocode = load_psv_and_report_memory(data_dir + 'VIC_ADDRESS_DEFAULT_GEOCODE_psv.psv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['ADDRESS_DETAIL_PID', 'DATE_CREATED', 'DATE_LAST_MODIFIED',\n",
       "        'DATE_RETIRED', 'BUILDING_NAME', 'LOT_NUMBER_PREFIX', 'LOT_NUMBER',\n",
       "        'LOT_NUMBER_SUFFIX', 'FLAT_TYPE_CODE', 'FLAT_NUMBER_PREFIX',\n",
       "        'FLAT_NUMBER', 'FLAT_NUMBER_SUFFIX', 'LEVEL_TYPE_CODE',\n",
       "        'LEVEL_NUMBER_PREFIX', 'LEVEL_NUMBER', 'LEVEL_NUMBER_SUFFIX',\n",
       "        'NUMBER_FIRST_PREFIX', 'NUMBER_FIRST', 'NUMBER_FIRST_SUFFIX',\n",
       "        'NUMBER_LAST_PREFIX', 'NUMBER_LAST', 'NUMBER_LAST_SUFFIX',\n",
       "        'STREET_LOCALITY_PID', 'LOCATION_DESCRIPTION', 'LOCALITY_PID',\n",
       "        'ALIAS_PRINCIPAL', 'POSTCODE', 'PRIVATE_STREET', 'LEGAL_PARCEL_ID',\n",
       "        'CONFIDENCE', 'ADDRESS_SITE_PID', 'LEVEL_GEOCODED_CODE', 'PROPERTY_PID',\n",
       "        'GNAF_PROPERTY_PID', 'PRIMARY_SECONDARY'],\n",
       "       dtype='object'),\n",
       " Index(['STREET_LOCALITY_PID', 'DATE_CREATED', 'DATE_RETIRED',\n",
       "        'STREET_CLASS_CODE', 'STREET_NAME', 'STREET_TYPE_CODE',\n",
       "        'STREET_SUFFIX_CODE', 'LOCALITY_PID', 'GNAF_STREET_PID',\n",
       "        'GNAF_STREET_CONFIDENCE', 'GNAF_RELIABILITY_CODE'],\n",
       "       dtype='object'),\n",
       " Index(['LOCALITY_PID', 'DATE_CREATED', 'DATE_RETIRED', 'LOCALITY_NAME',\n",
       "        'PRIMARY_POSTCODE', 'LOCALITY_CLASS_CODE', 'STATE_PID',\n",
       "        'GNAF_LOCALITY_PID', 'GNAF_RELIABILITY_CODE'],\n",
       "       dtype='object'),\n",
       " Index(['STATE_PID', 'DATE_CREATED', 'DATE_RETIRED', 'STATE_NAME',\n",
       "        'STATE_ABBREVIATION'],\n",
       "       dtype='object'),\n",
       " Index(['ADDRESS_DEFAULT_GEOCODE_PID', 'DATE_CREATED', 'DATE_RETIRED',\n",
       "        'ADDRESS_DETAIL_PID', 'GEOCODE_TYPE_CODE', 'LONGITUDE', 'LATITUDE'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_detail.columns, street_locality.columns,locality.columns, state.columns,address_geocode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc  # Import garbage collector interface\n",
    "\n",
    "# Perform merges with explicit suffix handling\n",
    "merged_data = address_detail.merge(street_locality, on='STREET_LOCALITY_PID', how='left', suffixes=('', '_sl'))\n",
    "merged_data.drop(merged_data.filter(regex='_sl$').columns.tolist(), axis=1, inplace=True)\n",
    "gc.collect()  # Explicitly call garbage collector\n",
    "\n",
    "merged_data = merged_data.merge(locality, on='LOCALITY_PID', how='left', suffixes=('', '_loc'))\n",
    "merged_data.drop(merged_data.filter(regex='_loc$').columns.tolist(), axis=1, inplace=True)\n",
    "gc.collect()  # Explicitly call garbage collector\n",
    "\n",
    "merged_data = merged_data.merge(state, on='STATE_PID', how='left', suffixes=('', '_st'))\n",
    "merged_data.drop(merged_data.filter(regex='_st$').columns.tolist(), axis=1, inplace=True)\n",
    "gc.collect()  # Explicitly call garbage collector\n",
    "\n",
    "merged_data = merged_data.merge(address_geocode, on='ADDRESS_DETAIL_PID', how='left', suffixes=('', '_geo'))\n",
    "merged_data.drop(merged_data.filter(regex='_geo$').columns.tolist(), axis=1, inplace=True)\n",
    "gc.collect()  # Explicitly call garbage collector\n",
    "\n",
    "# Filter by confidence and state abbreviation for Victoria\n",
    "filtered_data = merged_data[(merged_data['CONFIDENCE'] > -1) & (merged_data['STATE_ABBREVIATION'] == 'VIC')]\n",
    "\n",
    "del merged_data  # Delete the large merged_data object to free up memory\n",
    "gc.collect()  # Explicitly call garbage collector after deleting the object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_28252\\3853007981.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['Full Address'] = filtered_data.apply(format_address, axis=1)\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_28252\\3853007981.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  required_columns.rename(columns={'Full Address': 'Formatted Address', 'POSTCODE': 'Postcode'}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete and saved to filtered_victorian_addresses.csv.\n"
     ]
    }
   ],
   "source": [
    "# # Formatting the address\n",
    "# def format_address(row):\n",
    "#     # Format NUMBER_FIRST and FLAT_NUMBER as integers if not NaN\n",
    "#     number_first = int(row['NUMBER_FIRST']) if pd.notna(row['NUMBER_FIRST']) else ''\n",
    "#     flat_number = f\"{int(row['FLAT_NUMBER'])}/\" if pd.notna(row['FLAT_NUMBER']) else ''\n",
    "    \n",
    "#     # Assemble the full address using the formatted components\n",
    "#     # Include the STREET_TYPE_CODE if it is not empty or NaN\n",
    "#     street_type = row['STREET_TYPE_CODE'] if pd.notna(row['STREET_TYPE_CODE']) else ''\n",
    "#     return f\"{flat_number}{number_first} {row['STREET_NAME']} {street_type} {row['LOCALITY_NAME']} VIC {row['POSTCODE']}\"\n",
    "\n",
    "# # Apply the custom function to format the full address\n",
    "# filtered_data['Full Address'] = filtered_data.apply(format_address, axis=1)\n",
    "\n",
    "# # Select relevant columns and rename them for clarity\n",
    "# required_columns = filtered_data[['ADDRESS_DETAIL_PID', 'Full Address', 'POSTCODE']]\n",
    "# required_columns.rename(columns={'Full Address': 'Formatted Address', 'POSTCODE': 'Postcode'}, inplace=True)\n",
    "\n",
    "# # Save the formatted data to a CSV file\n",
    "# required_columns.to_csv(data_dir + 'filtered_victorian_addresses.csv', index=False)\n",
    "\n",
    "# print(\"Data processing complete and saved to filtered_victorian_addresses.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data contains 306375 records from specified postcodes.\n"
     ]
    }
   ],
   "source": [
    "# Define the list of postcodes of interest\n",
    "postcodes = [\n",
    "    3101, 3102, 3103, 3104, 3123, 3124, 3125, 3126, 3127, 3128, \n",
    "    3142, 3143, 3144, 3145, 3146, 3147, 3148, 3161, 3162, 3181, \n",
    "    3182, 3183, 3184, 3185, 3186, 3187, 3204\n",
    "]\n",
    "\n",
    "# Convert postcodes in dataframe to integers to ensure matching types\n",
    "filtered_data['POSTCODE'] = filtered_data['POSTCODE'].astype(int)\n",
    "\n",
    "# Filter the merged_data to only include rows with postcodes in the specified list\n",
    "filtered_data = filtered_data[filtered_data['POSTCODE'].isin(postcodes)]\n",
    "\n",
    "# Output the size of the filtered data to confirm the reduction\n",
    "print(f\"Filtered data contains {len(filtered_data)} records from specified postcodes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['FLAT_NUMBER'] = filtered_data['FLAT_NUMBER'].fillna(0).astype(int).astype(str)\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['NUMBER_FIRST'] = filtered_data['NUMBER_FIRST'].fillna(0).astype(int).astype(str)\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['FLAT_NUMBER'] = np.where(filtered_data['FLAT_NUMBER'] == '0', '', filtered_data['FLAT_NUMBER'] + '/')\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['STREET'] = filtered_data['FLAT_NUMBER'] + filtered_data['NUMBER_FIRST'] + ' ' + \\\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['STREET'] = filtered_data['STREET'].str.strip()\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['CITY'] = filtered_data['LOCALITY_NAME']\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['STATE'] = 'VIC'  # Assuming all addresses are in Victoria\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['ZIP'] = filtered_data['POSTCODE'].astype(str)  # Ensure ZIP is string\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['LAT'] = filtered_data['LATITUDE'].fillna('')\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['LON'] = filtered_data['LONGITUDE'].fillna('')\n",
      "C:\\Users\\ottend\\AppData\\Local\\Temp\\ipykernel_21284\\2990155578.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  required_columns.rename(columns={'ADDRESS_DETAIL_PID': 'Id', 'STREET': 'ADDRESS'}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete and saved to formatted_victorian_addresses.csv.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert NaN values for flat number and number first to empty string or zero before converting to int\n",
    "filtered_data['FLAT_NUMBER'] = filtered_data['FLAT_NUMBER'].fillna(0).astype(int).astype(str)\n",
    "filtered_data['NUMBER_FIRST'] = filtered_data['NUMBER_FIRST'].fillna(0).astype(int).astype(str)\n",
    "\n",
    "# Combine flat number and number first with conditions\n",
    "filtered_data['FLAT_NUMBER'] = np.where(filtered_data['FLAT_NUMBER'] == '0', '', filtered_data['FLAT_NUMBER'] + '/')\n",
    "filtered_data['STREET'] = filtered_data['FLAT_NUMBER'] + filtered_data['NUMBER_FIRST'] + ' ' + \\\n",
    "                          filtered_data['STREET_NAME'].fillna('') + ' ' + \\\n",
    "                          filtered_data['STREET_TYPE_CODE'].fillna('')\n",
    "\n",
    "# Strip extra spaces from the STREET column\n",
    "filtered_data['STREET'] = filtered_data['STREET'].str.strip()\n",
    "\n",
    "# Assign other address components\n",
    "filtered_data['CITY'] = filtered_data['LOCALITY_NAME']\n",
    "filtered_data['STATE'] = 'VIC'  # Assuming all addresses are in Victoria\n",
    "filtered_data['ZIP'] = filtered_data['POSTCODE'].astype(str)  # Ensure ZIP is string\n",
    "filtered_data['LAT'] = filtered_data['LATITUDE'].fillna('')\n",
    "filtered_data['LON'] = filtered_data['LONGITUDE'].fillna('')\n",
    "\n",
    "# Select relevant columns and rename them for clarity\n",
    "required_columns = filtered_data[['ADDRESS_DETAIL_PID', 'STREET', 'CITY', 'STATE', 'ZIP', 'LAT', 'LON']]\n",
    "required_columns.rename(columns={'ADDRESS_DETAIL_PID': 'Id', 'STREET': 'ADDRESS'}, inplace=True)\n",
    "\n",
    "# Save the formatted data to a CSV file\n",
    "required_columns.to_csv(data_dir + 'formatted_victorian_addresses.csv', index=False)\n",
    "\n",
    "print(\"Data processing complete and saved to formatted_victorian_addresses.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthplaces = [\n",
    "    # Major Australian Cities\n",
    "    \"Melbourne VIC AUS\", \"Sydney NSW AUS\", \"Brisbane QLD AUS\", \"Perth WA AUS\", \n",
    "    \"Adelaide SA AUS\", \"Canberra ACT AUS\", \"Hobart TAS AUS\", \"Darwin NT AUS\",\n",
    "\n",
    "    # Large Regional Australian Cities\n",
    "    \"Geelong VIC AUS\", \"Newcastle NSW AUS\", \"Wollongong NSW AUS\", \"Gold Coast QLD AUS\", \n",
    "    \"Townsville QLD AUS\", \"Cairns QLD AUS\", \"Toowoomba QLD AUS\", \"Ballarat VIC AUS\", \n",
    "    \"Bendigo VIC AUS\", \"Launceston TAS AUS\", \"Albury NSW AUS\", \"Mackay QLD AUS\", \n",
    "    \"Rockhampton QLD AUS\", \"Bunbury WA AUS\", \"Coffs Harbour NSW AUS\", \"Wagga Wagga NSW AUS\",\n",
    "\n",
    "    # Additional Australian Cities\n",
    "    \"Sunshine Coast QLD AUS\", \"Mildura VIC AUS\", \"Tamworth NSW AUS\", \"Shepparton VIC AUS\",\n",
    "    \"Alice Springs NT AUS\", \"Burnie TAS AUS\", \"Port Macquarie NSW AUS\", \"Devonport TAS AUS\",\n",
    "\n",
    "    # UK - Common places of birth for Australian migrants\n",
    "    \"London UK\", \"Manchester UK\", \"Birmingham UK\", \"Glasgow UK\", \"Liverpool UK\", \n",
    "    \"Edinburgh UK\", \"Bristol UK\", \"Leeds UK\", \"Sheffield UK\", \"Nottingham UK\",\n",
    "\n",
    "    # India - Common places of birth for Indian migrants in Australia\n",
    "    \"New Delhi IND\", \"Mumbai IND\", \"Bangalore IND\", \"Chennai IND\", \"Hyderabad IND\", \n",
    "    \"Ahmedabad IND\", \"Kolkata IND\", \"Pune IND\", \"Jaipur IND\", \"Lucknow IND\",\n",
    "\n",
    "    # China - Common places of birth for Chinese migrants in Australia\n",
    "    \"Beijing CHN\", \"Shanghai CHN\", \"Guangzhou CHN\", \"Shenzhen CHN\", \"Chengdu CHN\",\n",
    "    \"Tianjin CHN\", \"Hangzhou CHN\", \"Chongqing CHN\", \"Nanjing CHN\", \"Wuhan CHN\",\n",
    "\n",
    "    # Vietnam - Common places of birth for Vietnamese migrants in Australia\n",
    "    \"Ho Chi Minh City VNM\", \"Hanoi VNM\", \"Da Nang VNM\", \"Hai Phong VNM\",\n",
    "\n",
    "    # New Zealand - Common places of birth for Kiwi migrants in Australia\n",
    "    \"Auckland NZ\", \"Wellington NZ\", \"Christchurch NZ\", \"Hamilton NZ\", \"Dunedin NZ\",\n",
    "\n",
    "    # Additional Common Birthplaces for Australian Residents\n",
    "    \"Rome ITA\", \"Athens GRC\", \"Manila PHL\", \"Johannesburg ZAF\", \"Beirut LBN\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All patient data processed and saved with Australianised details.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_and_modify(filepath):\n",
    "    # Load the patient data\n",
    "    patients = pd.read_csv(filepath)\n",
    "\n",
    "    # Sample addresses randomly\n",
    "    sampled_addresses = required_columns.sample(n=len(patients), replace=True).reset_index(drop=True)\n",
    "\n",
    "    # Replace address-related columns and set COUNTY and FIPS to empty\n",
    "    address_columns = ['ADDRESS', 'CITY', 'STATE', 'ZIP', 'LAT', 'LON']\n",
    "    patients[address_columns] = sampled_addresses[address_columns]\n",
    "    patients['COUNTY'] = \"\"\n",
    "    patients['FIPS'] = \"\"\n",
    "\n",
    "    # Generate random Medicare-like numbers: format 4 5 1 (e.g., 1234 56789 1)\n",
    "    patients['SSN'] = np.random.randint(1000, 10000, size=len(patients)).astype(str) + ' ' + \\\n",
    "                      np.random.randint(10000, 100000, size=len(patients)).astype(str) + ' ' + \\\n",
    "                      np.random.randint(1, 10, size=len(patients)).astype(str)\n",
    "    \n",
    "    patients['BIRTHPLACE'] = np.random.choice(birthplaces, size=len(patients), replace=True)\n",
    "\n",
    "    return patients\n",
    "\n",
    "\n",
    "# Load, modify, and save the Train data\n",
    "train_data_path = '../data/Train/csv/patients.csv'\n",
    "modified_train_patients = load_and_modify(train_data_path)\n",
    "modified_train_patients.to_csv('../data/Train/csv/patients_australianised.csv', index=False)\n",
    "\n",
    "# Load, modify, and save the Test data\n",
    "test_data_path = '../data/Test/csv/patients.csv'\n",
    "modified_test_patients = load_and_modify(test_data_path)\n",
    "modified_test_patients.to_csv('../data/Test/csv/patients_australianised.csv', index=False)\n",
    "\n",
    "print(\"All patient data processed and saved with Australianised details.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
